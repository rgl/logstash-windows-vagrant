# see https://www.elastic.co/guide/en/logstash/current/event-dependent-configuration.html

input {
  http {
    host => "127.0.0.1"
    port => 8080
    codec => json
    type => "http"
  }

  gelf {
    host => "127.0.0.1"
    port => 12201
    type => "gelf"
  }

  # NB by default the syslog filter only handles the older RFC3164 syslog format.
  # NB to handle RFC5424 syslog format (as used by Serilog.Sinks.Syslog).
  #    there are dragons at https://github.com/logstash-plugins/logstash-input-syslog/issues/15
  #    and https://rfc5424-logging-handler.readthedocs.io/en/latest/syslog_server.html
  syslog {
    host => "127.0.0.1"
    port => 514
    type => "syslog"
  }

  # NB used by erlang-lager-logstash-udp
  udp {
    host => "127.0.0.1"
    port => 9125
    codec => "json"
  }

  # NB used by winlogbeat.
  beats {
    host => "127.0.0.1"
    port => 5044
    type => "beats"
  }
}

filter {
  if [type] == "beats" {
    mutate {
      add_field => {
        "[@metadata][index]" => "%{[agent][type]}-%{[agent][version]}-%{+yyyy.MM.dd}"
      }
    }
  } else {
    mutate {
      add_field => {
        "[@metadata][index]" => "logstash-%{+yyyy.MM.dd}"
      }
    }
  }

  if [type] == "http" and [headers][request_path] == "/serilog" {
    # serilog Serilog.Sinks.Http sends logs as a log object with a batch of events alike the one sent by the examples/csharp-serilog-http application:
    #
    #   {
    #     "events": [{
    #       "Timestamp": "2019-02-26T19:57:19.6176770+00:00",
    #       "Level": "Information",
    #       "MessageTemplate": "Begin",
    #       "RenderedMessage": "Begin",
    #       "Properties": {
    #         "SourceContext": "SerilogHttp.Program",
    #         "Application": "csharp-serilog-http/1.0"
    #       }
    #     }, {
    #       "Timestamp": "2019-02-26T19:57:19.6427687+00:00",
    #       "Level": "Debug",
    #       "MessageTemplate": "Dividing {A} by {B}",
    #       "RenderedMessage": "Dividing 10 by 0",
    #       "Properties": {
    #         "A": 10,
    #         "B": 0,
    #         "SourceContext": "SerilogHttp.Program",
    #         "Application": "csharp-serilog-http/1.0",
    #         "TraceId": "f3b588fcac6d47998c70f2cb7499ed2c"
    #       }
    #     }, {
    #       "Timestamp": "2019-02-26T19:57:19.6458642+00:00",
    #       "Level": "Error",
    #       "MessageTemplate": "Something went wrong with the division",
    #       "RenderedMessage": "Something went wrong with the division",
    #       "Exception": "System.DivideByZeroException: Attempted to divide by zero.\r\n   at SerilogHttp.Program.Main(String[] args) in C:\\vagrant\\examples\\csharp-serilog-http\\Program.cs:line 50",
    #       "Properties": {
    #         "SourceContext": "SerilogHttp.Program",
    #         "Application": "csharp-serilog-http/1.0",
    #         "TraceId": "f3b588fcac6d47998c70f2cb7499ed2c"
    #       }
    #     }]
    #   }
    #
    # the logstash http plugin will augment the log object with several properties:
    #
    #   type          the type set in the configuration of the http input plugin
    #   host          the ip address of the host that sent the log message
    #   headers       headers from the http request sent by serilog
    #   @version      the event type version
    #   @timestamp    the time when logstash received the log message
    #
    # the log object will end-up being something alike:
    #
    #   {
    #     "type": "http",
    #     "host": "127.0.0.1",
    #     "@version": "1",
    #     "headers": {
    #       "http_version": "HTTP/1.1",
    #       "content_type": "application/json; charset=utf-8",
    #       "request_method": "POST",
    #       "request_path": "/",
    #       "http_user_agent": null,
    #       "http_accept": null,
    #       "content_length": "1254",
    #       "http_host": "localhost:8080"
    #     },
    #     "@timestamp": "2019-02-26T19:57:20.278Z",
    #     "events": [{
    #       ...
    #     }]
    #   }

    # remove unneeded fields.
    mutate {
      remove_field => ["headers", "host"]
    }

    # split the batch into single events (because Serilog.Sinks.Http sends log lines in batches).
    #
    # example:
    #
    #  http --verbose post 127.0.0.1:8080/serilog events:='[{"Timestamp":"2019-01-01T00:00:01.1234567+00:00","RenderedMessage":"one"},{"Timestamp":"2019-01-01T00:00:02.1234567+00:00","RenderedMessage":"two"}]'
    split {
      field => "events"
      target => "serilog"
      remove_field => "events"
    }

    # parse Timestamp as the event @timestamp.
    #
    # example:
    #
    #   http --verbose post 127.0.0.1:8080/serilog events:='[{"Timestamp":"2019-01-02T03:04:05.1234567+01:00"}]'
    #
    #  this date filter will transform:
    #    2019-01-02T03:04:05.1234567+01:00
    #  into:
    #    2019-01-02T02:04:05.123Z
    #
    # NB it correctly normalizes the timestamp to UTC
    # NB it looses a bit of precision
    date {
      match => ["[serilog][Timestamp]", "ISO8601"]
    }
  } else if [type] == "http" and [headers][request_path] == "/log4j2" {
    # the log4j2 Http appender with the Json layout sends a single log per http request alike the one sent by the examples/java-log4j2-http application:
    #
    #   {
    #     "thread": "main",
    #     "level": "INFO",
    #     "loggerName": "net.example.Example",
    #     "message": "Begin",
    #     "endOfBatch": false,
    #     "loggerFqcn": "org.apache.logging.log4j.spi.AbstractLogger",
    #     "instant": {
    #       "epochSecond": 1551296422,
    #       "nanoOfSecond": 406000000
    #     },
    #     "threadId": 1,
    #     "threadPriority": 5
    #   }
    #   {
    #     "thread": "main",
    #     "level": "DEBUG",
    #     "loggerName": "net.example.Example",
    #     "message": "Dividing 10 by 0",
    #     "endOfBatch": false,
    #     "loggerFqcn": "org.apache.logging.log4j.spi.AbstractLogger",
    #     "instant": {
    #       "epochSecond": 1551296422,
    #       "nanoOfSecond": 938000000
    #     },
    #     "threadId": 1,
    #     "threadPriority": 5
    #   }    
    #   {
    #     "thread": "main",
    #     "level": "ERROR",
    #     "loggerName": "net.example.Example",
    #     "message": "Something went wrong with the division",
    #     "thrown": {
    #       "commonElementCount": 0,
    #       "localizedMessage": "/ by zero",
    #       "message": "/ by zero",
    #       "name": "java.lang.ArithmeticException",
    #       "extendedStackTrace": [
    #         {
    #           "class": "net.example.Example",
    #           "method": "main",
    #           "file": "Example.java",
    #           "line": 30,
    #           "exact": true,
    #           "location": "example-1.0.0.jar",
    #           "version": "1.0.0"
    #         }
    #       ]
    #     },
    #     "endOfBatch": false,
    #     "loggerFqcn": "org.apache.logging.log4j.spi.AbstractLogger",
    #     "instant": {
    #       "epochSecond": 1551296422,
    #       "nanoOfSecond": 985000000
    #     },
    #     "threadId": 1,
    #     "threadPriority": 5
    #   }
    #
    # the logstash http plugin will augment the log object with several properties:
    #
    #   type          the type set in the configuration of the http input plugin
    #   host          the ip address of the host that sent the log message
    #   headers       headers from the http request sent by log4j2
    #   @version      the event type version
    #   @timestamp    the time when logstash received the log message (iif the message does not contain that property)
    #
    # the log object will end-up being something alike:
    #
    #   {
    #     "type": "http",
    #     "host": "127.0.0.1",
    #     "headers": {
    #       "request_method": "POST",
    #       "http_accept": "text/html, image/gif, image/jpeg, *; q=.2, */*; q=.2",
    #       "connection": "keep-alive",
    #       "content_type": "application/json; charset=UTF-8",
    #       "http_version": "HTTP/1.1",
    #       "request_path": "/log4j2",
    #       "http_host": "127.0.0.1:8080",
    #       "content_length": "257",
    #       "http_user_agent": "Java/1.8.0_201"
    #     },
    #     "@version": "1",
    #     "@timestamp": "2019-02-27T19:40:22.781Z",
    #     ...
    #   }

    # remove unneeded fields.
    mutate {
      remove_field => ["headers", "host"]
    }

    # parse instant as the event @timestamp.
    #
    # example:
    #
    #   http --verbose post 127.0.0.1:8080/log4j2 instant:='{"epochSecond":1551296422,"nanoOfSecond":406000000}'
    #   Invoke-RestMethod -Method Post -Uri http://127.0.0.1:8080/log4j2 -ContentType 'application/json' -Body '{"instant":{"epochSecond":1551296422,"nanoOfSecond":406000000}}'
    #
    # this date filter will transform:
    #   {
    #     "epochSecond": 1551296422,
    #     "nanoOfSecond": 406000000
    #   }
    # into:
    #   2019-02-27T21:08:17.406Z
    #
    # NB it looses a bit of precision
    # NB we could also send the @timestamp property directly from the log4j2 application
    #    (see the log4j2.properties file) but we have this here as an example.
    mutate {
      add_field => {
        "[@metadata][timestamp]" => "%{[instant][epochSecond]}.%{[instant][nanoOfSecond]}"
      }
      remove_field => ["instant"]
    }
    date {
      match => ["[@metadata][timestamp]", "UNIX"]
    }
  } else if [type] == "gelf" {
    mutate {
      remove_field => ["short_message"]
    }
  }

  # remove the temporay type attribute that was used to filter the filters.
  mutate {
    remove_field => ["type"]
  }
}

output {
  stdout {
    codec => json_lines
  }
  elasticsearch {
    hosts => ["127.0.0.1:9200"]
    index => "%{[@metadata][index]}"
    # logstash will automatically manage the elasticsearch template; to
    # use a custom one, use the template option.
    # NB the template source originally comes from the git repository at, e.g.:
    #       https://github.com/logstash-plugins/logstash-output-elasticsearch/blob/v7.4.2/lib/logstash/outputs/elasticsearch/elasticsearch-template-es6x.json
    #    which you can use as a base.
    #template => 'logstash-elasticsearch-template.json'
  }
}
